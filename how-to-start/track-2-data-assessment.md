# ğŸ” Track 2 (Data Assessment)

This track focuses on finding and evaluating valuable and relevant at-risk data. This helps others be able to complete capturing tasks as they can depend on your â€œpeer reviewedâ€ assessment.

**Tech Skill Level:** Intermediate

**Time Commitment:** \~2 hours

**Tasks Include:**

1. Identify & submit at-risk web pages
2. Collect at-risk individual web pages

**Tools Required (vary across tasks):**

1. Wayback Machine extension/add-on
   1. [Chrome Extension](https://chromewebstore.google.com/detail/wayback-machine/fpnmgdkabkmnadcjpehmlllkndpkmiak?pli=1)
   2. [Firefox add-on](https://web.archive.org/web/20230212035050/https://addons.mozilla.org/en-US/firefox/addon/wayback-machine_new/)
   3. [Safari Extension](https://web.archive.org/web/20230212035050/https://apps.apple.com/us/app/wayback-machine/id1472432422)
   4. [iOS app](https://web.archive.org/web/20230212035050/https://itunes.apple.com/us/app/wayback-machine/id1201888313)
   5. [Android app](https://web.archive.org/web/20230212035050/https://play.google.com/store/apps/details?id=com.archive.waybackmachine)
2. Spreadsheet editor (excel, google sheets)

**Breakdown of Task Sections**\
ğŸš _(helicopter emoji)_ gives summary of task\
ğŸ—‚ï¸ _(index dividers)_ outlines specific steps needed to complete task\
ğŸ› ï¸ _(hammer & wrench emoji)_ details skills & tools needed for task\
ğŸ’ _(information desk person)_ details participant role

### SUGGESTED TASKS & INSTRUCTIONS

#### 1. <mark style="background-color:purple;">Identify & suggest at-risk web pages</mark>

ğŸš**Summary:** Volunteers will search through the web for web pages, single files, and other online information that may be considered at-risk data from sources like federal agencies, state and regional offices, or national or local environmental organizations and groups.

ğŸ’**Role:** Browser

ğŸ—‚ï¸**Workflow:**&#x20;

* Review established collecting criteria to see if the webpage/website/dataset falls within this Data Rescue scope
  * NOTE: suggestions will be captured and/or deposited to 1 of the following repositories&#x20;
    * [End of Term](https://eotarchive.org/) (EoT) : Mostly includes and collects webpages and files related to specific presidential administrations
    * &#x20;[Internet Archive](https://archive.org/about/): more broad collecting scope. Tends to capture web content (meaning webpages or part of websites) Harder to upload actual files.&#x20;
* Research, name, and document web pages (individual pages or a small batch of pages within a website.&#x20;
  * For a large quantity of web pages or complex large websites, see Track 3.
* Submit basic information about the web page on this Data Tracking Form [**Link to Data Tracking Form**].&#x20;

ğŸ› ï¸**Skills Needed:** Be able to browse through web pages to assess value or significance of content then be able to access a google form to submit assessment and basic metadata (details about the webpage/website)

#### <mark style="background-color:purple;">2. Describe collected webpages/records</mark>&#x20;

ğŸš**Summary**: Description (at times also called metadata) helps with the management and access to digital records. Information about the content and context helps with identification, assessment, and verification of authenticity.

ğŸ’**Role:** Metadata Reporter

ğŸ—‚ï¸**Workflow**

* Read [dublin core basic manual ](https://www.dublincore.org/specifications/dublin-core/usageguide/)to learn about the use of metadata for digital records (for explanation on selected metadata fields, see section 4. Elements)
* Navigate to the [**link to Data Tracking List**] sheet (stay on the first tab â€œEDIT TO THIS TABLEâ€)&#x20;
* Select a row with an item that is marked as "Needs Metadata" (this info found in column K)
* Fill-in descriptive text for your select row for all 5 metadata columns (these are columns P through U colored in teal blue)
* Use Data Tracking sheet for title and URL to find other information to create description
* When metadata has been entered, change status of row in column K to "Needs Checksum" &#x20;

ğŸ› ï¸Skills Needed Have reading and writing literacy in English language to create metadata in English. Ability to distinguish between different types of metadata fields (who, what, when. where, how)

#### <mark style="background-color:purple;">3. Contribute capture suggestions for select repositories (</mark>[<mark style="background-color:purple;">End of Term (EoT</mark>](https://eotarchive.org/)<mark style="background-color:purple;">) or</mark> [<mark style="background-color:purple;">Internet Archive</mark>](https://archive.org/)<mark style="background-color:purple;">) collection</mark>

ğŸš**Summary:** Participants in this track will browse a specific set of suggested at-risk federal webpages to search for ones that need to be preserved.&#x20;

ğŸ’**Role:** Data Assessor

ğŸ—‚ï¸**Workflow:**&#x20;

* Reference this [**Link to Data Tracking Form**] that are ready for archiving
* Select a row
* Change row Status to â€œIn-progress - Capture â€
* To capture, decide if it goes to the Internet Archive or the End of Term project
  * Internet Archive-  use [Chrome](https://chromewebstore.google.com/detail/wayback-machine/fpnmgdkabkmnadcjpehmlllkndpkmiak?pli=1), [Firefox](https://addons.mozilla.org/en-US/firefox/addon/wayback-machine_new/), or [Safari](https://apps.apple.com/us/app/wayback-machine/id1472432422) browser extension to capture webpage OR entr URL directly via the Wayack Machine (navigate to "[Save Page Now](http://web.archive.org/)" option)
  * End of Term - use the project's [nomination form](https://digital2.library.unt.edu/nomination/eth2024/add/) to add URL, title, & government data type
* Update row status to â€œCaptured" on the spreadsheet
* Repeat process for a new submission

ğŸ› ï¸**Skills Needed:** Be able to browse through web pages and use a browser extension button (listed in above Tools Required) to notify the Internet Archive or the End of Term project, which has been preserving federal webpages since 2008. Once the URL to the web page has been submitted to Internet Archive, the EoT will automatically process the webpage for long term preservation into their repository.
